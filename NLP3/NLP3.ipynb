{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the JSON file\n",
    "tips = []\n",
    "with open('C:\\\\Users\\\\ali\\\\OneDrive\\\\Desktop\\\\yelp_academic_dataset_tip.json', 'r') as f:\n",
    "    for line in f:\n",
    "        tip = json.loads(line)\n",
    "        tips.append(tip)\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(tips)\n",
    "# Save the DataFrame as a CSV file\n",
    "df.to_csv('yelp_tips.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                            Avengers time with the ladies.\n",
      "1         They have lots of good deserts and tasty cuban...\n",
      "2                    It's open even when you think it isn't\n",
      "3                                 Very decent fried chicken\n",
      "4                    Appetizers.. platter special for lunch\n",
      "                                ...                        \n",
      "908910                Disappointed in one of your managers.\n",
      "908911                              Great food and service.\n",
      "908912                                  Love their Cubans!!\n",
      "908913                              Great pizza great price\n",
      "908914                    Food is good value but a bit hot!\n",
      "Name: text, Length: 908915, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tips_df = pd.read_csv('yelp_tips.csv')\n",
    "\n",
    "# Extract the 'text' attribute from the tips file\n",
    "corpus = tips_df['text']\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    clean = re.sub(r'[^\\w\\s]', '', text)\n",
    "    normalized=clean.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(normalized)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens\n",
    "corpus = corpus.dropna()\n",
    "# Apply preprocessing to each document in the corpus\n",
    "processed_corpus = corpus.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               [avenger, time, lady]\n",
      "1         [lot, good, desert, tasty, cuban, sandwich]\n",
      "2                           [open, even, think, isnt]\n",
      "3                            [decent, fried, chicken]\n",
      "4                [appetizer, platter, special, lunch]\n",
      "                             ...                     \n",
      "908910                   [disappointed, one, manager]\n",
      "908911                         [great, food, service]\n",
      "908912                                  [love, cuban]\n",
      "908913                   [great, pizza, great, price]\n",
      "908914                  [food, good, value, bit, hot]\n",
      "Name: text, Length: 908901, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FastText model\n",
    "model_fasttext = FastText(processed_corpus, window=5, min_count=5, workers=4, sg=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: amaretto\n",
      "Closest: ['sorbetto', 'cioccolato', 'ganache', 'pistachio', 'marscapone', 'macadamia', 'meringue', 'creama', 'cardamom', 'crème']\n",
      "Furthest: ['senior', 'inspected', 'inspect', 'safety', 'depart', 'inspector', 'departs', 'rate', 'inspection', 'resource']\n",
      "\n",
      "Word: favs\n",
      "Closest: ['faves', 'fav', 'favorite', 'fave', 'fava', 'favorito', 'favourite', 'favour', 'wordawesome', 'musthaves']\n",
      "Furthest: ['urn', 'rm', 'enforce', 'enforced', 'urgency', 'emergency', 'violation', 'wage', 'internet', 'vaccine']\n",
      "\n",
      "Word: lusherpride\n",
      "Closest: ['guardiansofthegroove', 'phrasesfromplaces', 'nolalivemusic', 'dirtycoast', 'civicnola', 'algiersferry', 'uptownnola', 'lusher', 'thedandywarhols', 'nolaliving']\n",
      "Furthest: ['accommodate', 'split', 'accommodated', 'carryout', 'ordering', 'amount', 'requested', 'request', 'offered', 'medium']\n",
      "\n",
      "Word: torture\n",
      "Closest: ['pasture', 'breathing', 'rapture', 'gesture', 'breather', 'snide', 'interruption', 'posture', 'cesspool', 'streamline']\n",
      "Furthest: ['ri', 'fave', 'ni', 'ftw', '241', 'bogo', 'vodka', 'mf', 'oz', 'jai']\n",
      "\n",
      "Word: 810pm\n",
      "Closest: ['710pm', '910pm', '410pm', '510pm', '610pm', '210pm', '4pm10pm', '10pm', '8am10pm', '89pm']\n",
      "Furthest: ['us', 'che', 'dal', 'texture', 'dent', 'lac', 'und', 'fake', 'undo', 'con']\n",
      "\n",
      "Word: filth\n",
      "Closest: ['filthy', 'urine', 'infested', 'disgusting', 'bedbug', 'disgust', 'disgusted', 'mop', 'disinfectant', 'unsanitary']\n",
      "Furthest: ['monte', 'ita', 'frittata', 'cristo', 'empanadas', 'jo', 'pau', 'sammie', 'cravin', 'bentos']\n",
      "\n",
      "Word: 5min\n",
      "Closest: ['25min', '1015min', '15min', '45min', '10min', '30minute', '40min', '30min', '20minute', '30minutes']\n",
      "Furthest: ['eco', 'petit', 'salvadoran', 'vodka', 'sante', 'inspired', 'yogurt', 'faves', 'flavor', 'ju']\n",
      "\n",
      "Word: partition\n",
      "Closest: ['demolition', 'tuition', 'ignition', 'proposition', 'petition', 'recognition', 'transition', 'audition', 'pollution', 'incarnation']\n",
      "Furthest: ['tini', 'goood', 'gooood', 'goooood', 'gooooood', 'goooooood', 'gooooooood', 'goooooooood', 'goooo', 'yummm']\n",
      "\n",
      "Word: save\n",
      "Closest: ['saver', 'saved', 'saving', 'waste', 'money', 'wasted', 'savvy', 'wast', 'spend', 'adhere']\n",
      "Furthest: ['hip', 'jai', 'ty', 'hello', 'ai', 'ken', 'ra', 'smokin', 'tai', 'ed']\n",
      "\n",
      "Word: panera\n",
      "Closest: ['paneras', 'pane', 'subway', 'starbuck', 'pdq', 'zaxbys', 'starbucks', 'publix', 'kroger', 'tjs']\n",
      "Furthest: ['bud', 'led', 'sexy', '3d', 'scotch', 'hunt', 'tu', 'rare', 'tequila', 'tue']\n",
      "\n",
      "Word: attacked\n",
      "Closest: ['attack', 'attach', 'stacked', 'attachment', 'dialed', 'hacked', 'attached', 'whacked', 'jacked', 'racked']\n",
      "Furthest: ['ba', 'tea', 'belgian', 'colombian', 'chai', 'sai', 'wine', 'baba', 'latte', 'tequila']\n",
      "\n",
      "Word: varying\n",
      "Closest: ['frying', 'implementing', 'heaping', 'qualifying', 'carrying', 'limiting', 'splendor', 'copying', 'various', 'varietal']\n",
      "Furthest: ['ri', 'fuckin', 'fuck', 'lin', 'kann', 'sa', 'jos', 'ma', 'jenn', 'bobby']\n",
      "\n",
      "Word: limon\n",
      "Closest: ['limo', 'riquísimo', 'limonada', 'limpio', 'pésimo', 'benicio', 'cacio', 'mio', 'caldo', 'mauricio']\n",
      "Furthest: ['urn', 'clothes', 'cloth', 'teenage', 'tend', 'ing', 'organized', 'teen', 'kid', 'nt']\n",
      "\n",
      "Word: gras\n",
      "Closest: ['mardi', 'mardigras', 'grasp', 'mardis', 'foie', 'mardigras2015', 'lundi', 'parade', 'zaras', 'madras']\n",
      "Furthest: ['worked', 'worker', 'working', 'salsa', 'towel', 'asked', 'charge', 'asking', 'toned', 'questioned']\n",
      "\n",
      "Word: reveal\n",
      "Closest: ['reviver', 'rebekah', 'revel', 'solicitous', 'kunefe', 'affair', 'rev', 'revue', 'deidre', 'revival']\n",
      "Furthest: ['dunkin', 'drivethru', 'starbucks', 'gas', 'bagel', 'wawa', 'cv', '247', 'mc', 'sbucks']\n",
      "\n",
      "Word: multicolored\n",
      "Closest: ['colored', 'discolored', 'multitask', 'multi', 'watercolor', 'cologne', 'allnatural', 'fermented', 'perplexed', 'coloring']\n",
      "Furthest: ['parking', 'shuttle', 'close', 'parkin', 'thu', '1am', '2am', '5am', 'thurs', 'thur']\n",
      "\n",
      "Word: jockey\n",
      "Closest: ['hockey', 'sockeye', 'mickey', 'dickey', 'pacman', 'buckeye', 'hawkeye', 'hockessin', 'softball', 'lsu']\n",
      "Furthest: ['medi', 'pupusas', 'brazilian', 'ethiopia', 'eta', 'cafe', 'flavour', 'rely', 'medium', 'latte']\n",
      "\n",
      "Word: eaten\n",
      "Closest: ['ive', 'weve', 'ate', 'tastiest', 'uneaten', 'craved', 'hadand', 'havent', 'gotten', 'saddest']\n",
      "Furthest: ['pin', 'vin', 'ua', 'tu', 'lug', 'shirt', 'dora', 'sunglass', 'ski', 'jean']\n",
      "\n",
      "Word: baja\n",
      "Closest: ['raja', 'roja', 'tostados', 'adobada', 'sopes', 'asado', 'taquitos', 'guadalajara', 'quesabirria', 'pastor']\n",
      "Furthest: ['lobby', 'older', 'ge', 'wireless', 'chest', '70', 'passage', 'pump', 'registration', 'massage']\n",
      "\n",
      "Word: mere\n",
      "Closest: ['chevre', 'bere', 'sucre', 'merit', 'chevelle', 'chouteau', 'cheshire', 'biere', 'deidre', 'meridien']\n",
      "Furthest: ['ing', 'karaoke', 'in', 'fryer', 'wash', 'tsa', '11pm', '1pm', 'annoying', 'dryer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "random_words = random.sample(model_fasttext.wv.index_to_key, 20)\n",
    "\n",
    "# Find closest and furthest words for each random word\n",
    "results = {}\n",
    "for word in random_words:\n",
    "    closest = model_fasttext.wv.most_similar(word, topn=10)\n",
    "    furthest = model_fasttext.wv.most_similar(negative=[word], topn=10)\n",
    "    results[word] = {'closest': closest, 'furthest': furthest}\n",
    "\n",
    "# Print results\n",
    "for word, similar_words in results.items():\n",
    "    print(\"Word:\", word)\n",
    "    print(\"Closest:\", [w[0] for w in similar_words['closest']])\n",
    "    print(\"Furthest:\", [w[0] for w in similar_words['furthest']])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amaretto', 'favs', 'lusherpride', 'torture', '810pm', 'filth', '5min', 'partition', 'save', 'panera', 'attacked', 'varying', 'limon', 'gras', 'reveal', 'multicolored', 'jockey', 'eaten', 'baja', 'mere']\n"
     ]
    }
   ],
   "source": [
    "print(random_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: amaretto\n",
      "Closest: ['Amaretto', 'Frangelico', 'frangelico', 'liqueur', 'kahlua', 'anisette', 'cointreau', 'amaretti', 'limoncello', 'Kahlua']\n",
      "Furthest: ['SDMS', 'ASTRO', 'HealthWatch', 'ITEX', 'KAMS', 'SEWA', 'SEMI', 'IDSA', 'SGIA', 'SSTI']\n",
      "\n",
      "Word: favs\n",
      "Closest: ['faves', 'fav', 'fave', 'fav.', 'favs.', 'favorties', 'FAVE', 'favortie', 'fave.', 'favorites']\n",
      "Furthest: ['...................................................................................................................................', '..........................................................................................................................................', '.........................................................................................................................................', '............................................................................................................................................', '.............................................................................................................................................', '...........................................................................................................................................', '.......................................................................................................................................', '...............................................................................................................................', '.....................................................................................................................................', '........................................................................................................................................']\n",
      "\n",
      "Word: lusherpride\n",
      "Closest: ['airplanealertapp-downloadarrow-downarrow-expandarrow-leftarrow-right-alternatearrow-rightarrow-upattractionbadgeballoonsbarcodebellbookbuildingcalendarcameracarcartcash-backchairchat-dotschatcheck-circlecheckboxclosecomputercreatecruiseemptybadgeenvelope-open-outlineenvelope-openenvelopefacebookfingerflowerfoodfootballgeargift-cardgiftgridguitarhealthheart-outlinehearthome-gardeninfojewellifetime-cashbacklipsticklocationlockmapmedalmenuminus-circlemoneynewsomnichannelpacifierpaperclippawphoneplayplugplusprintpromotedquestion-markrebatermn-rsearchshareshirtshoeslidersstar-outlinestarstopwatchstoretag-addtagthumbs-downthumbs-uptoytrophyuserwatchx', 'DEky4M0BSpUOTPnSpkuL5I0GTSnRI4jMepcaFAoxIoFnX5kmJQk1aYvr2odGBAAIfkECQoABAAsCQAAABAAEgAACGcAARAYSLCgQQEABBokkFAhAQEQHQ4EMKCiQogRCVKsOOAiRocbLQ7EmJEhR4cfEWoUOTFhRIUNE44kGZOjSIQfG9rsyDCnzp0AaMYMyfNjS6JFZWpEKlDiUqALJ0KNatKmU4NDBwYEACH5BAkKAAQALAkAAAAQABIAAAhpAAEQGEiQIICDBAUgLEgAwICHAgkImBhxoMOHAyJOpGgQY8aBGxV2hJgwZMWLFTcCUIjwoEuLBym69PgxJMuDNAUqVDkz50qZLi', 'DEky4M0BSpUOTPnSpkuL5I0GTSnRI4jMepcaFAoxIoFnX5kmJQk1aYvr2odGBAAIfkECQoABAAsCQAAABAAEgAACGcAARAYSLCgQQEABBokkFAhAQEQHQ4EMKCiQogRCVKsOOAiRocbLQ7EmJEhR4cfEWoUOTFhRIUNE44kGZOjSIQfG9rsyDCnzp0AaMYMyfNjS6JFZWpEKlDiUqALJ0KNatKmU4NDBwYEACH5BAUKAAQALAkAAAAQABIAAAhpAAEQGEiQIICDBAUgLEgAwICHAgkImBhxoMOHAyJOpGgQY8aBGxV2hJgwZMWLFTcCUIjwoEuLBym69PgxJMuDNAUqVDkz50qZLi', '60-post-invoice-ninja-free-open-source-invoicing-amp-time-tracking-opposenewapstandardsus', 'GaelicSerbianSesothoShonaSindhiSinhalaSlovakSlovenianSomaliSpanishSudaneseSwahiliSwedishTajikTamilTeluguThaiTurkishUkrainianUrduUzbekVietnameseWelshXhosaYiddishYorubaZulu', 'crescendosexibloguerobateyabsorbersexiindesignabledinerolatifundiosexibrezarcularsutesexirapoplinbrezarcorrentosoVd.lazadareflejoreglafeministabrezarchuzasexiouttiqueblogueroin', '6-post-how-to-make-an-invoice-with-sample-invoices-wikihow-opposenewapstandardsus', 'ZJiUJNWmL69qHRgQACH5BAkKAAQALAkAAAAQABIAAAhnAAEQGEiwoEEBAAQaJJBQIQEBEB0OBDCgokKIEQlSrDjgIkaHGy0OxJiRIUeHHxFqFDkxYUSFDROOJBmTo0iEHxva7Mgwp86dAGjGDMnzY0uiRWVqRCpQ4lKgCydCjWrSplODQwcGBAAh', '60-post-invoice-ninja-free-open-source-invoicing-amp-time-tracking-lacey-chabertus', '60-post-invoice-ninja-free-open-source-invoicing-amp-time-tracking-ediblewildsus']\n",
      "Furthest: ['ãŽã', '\\U00100077', '\\U00100071', '\\U00100040', 'Cve', 'FollowPatrick', 'Shannonfrom', 'MattCAG', 'trse', '\\U00100068']\n",
      "\n",
      "Word: torture\n",
      "Closest: ['torture.The', 'water-boarding', 'Torture', 'tortures', 'torture-', 'torturing', 'toture', 'waterboarding', 'torture.I', 'torturers']\n",
      "Furthest: ['BusinessWest', 'Bryte', 'Muckey', 'TMCF', 'Cayzer', 'Beiträge', 'NetSpot', 'CCEDC', 'PlaneSense', 'EveryoneOn']\n",
      "\n",
      "Word: 810pm\n",
      "Closest: ['ShippingMJM', 'deblogueroreflejoantecedentesexitlacuachebateysuteindesignableabsorbersexilatifundiosexibrezarsutemultiétnicosexiplinrapobrezarcorrentosoVd.lazadafisiochillidomabrezarsico-chuzaoutcolodrablogueroin', 'BLOGTWITTERYOUTUBEFACEBOOKTUMBLRTOONZONEFAQ', 'DEky4M0BSpUOTPnSpkuL5I0GTSnRI4jMepcaFAoxIoFnX5kmJQk1aYvr2odGBAAIfkECQoABAAsCQAAABAAEgAACGcAARAYSLCgQQEABBokkFAhAQEQHQ4EMKCiQogRCVKsOOAiRocbLQ7EmJEhR4cfEWoUOTFhRIUNE44kGZOjSIQfG9rsyDCnzp0AaMYMyfNjS6JFZWpEKlDiUqALJ0KNatKmU4NDBwYEACH5BAkKAAQALAkAAAAQABIAAAhpAAEQGEiQIICDBAUgLEgAwICHAgkImBhxoMOHAyJOpGgQY8aBGxV2hJgwZMWLFTcCUIjwoEuLBym69PgxJMuDNAUqVDkz50qZLi', 'DEky4M0BSpUOTPnSpkuL5I0GTSnRI4jMepcaFAoxIoFnX5kmJQk1aYvr2odGBAAIfkECQoABAAsCQAAABAAEgAACGcAARAYSLCgQQEABBokkFAhAQEQHQ4EMKCiQogRCVKsOOAiRocbLQ7EmJEhR4cfEWoUOTFhRIUNE44kGZOjSIQfG9rsyDCnzp0AaMYMyfNjS6JFZWpEKlDiUqALJ0KNatKmU4NDBwYEACH5BAUKAAQALAkAAAAQABIAAAhpAAEQGEiQIICDBAUgLEgAwICHAgkImBhxoMOHAyJOpGgQY8aBGxV2hJgwZMWLFTcCUIjwoEuLBym69PgxJMuDNAUqVDkz50qZLi', 'GaelicSerbianSesothoShonaSindhiSinhalaSlovakSlovenianSomaliSpanishSudaneseSwahiliSwedishTajikTamilTeluguThaiTurkishUkrainianUrduUzbekVietnameseWelshXhosaYiddishYorubaZulu', 'ZJiUJNWmL69qHRgQACH5BAkKAAQALAkAAAAQABIAAAhnAAEQGEiwoEEBAAQaJJBQIQEBEB0OBDCgokKIEQlSrDjgIkaHGy0OxJiRIUeHHxFqFDkxYUSFDROOJBmTo0iEHxva7Mgwp86dAGjGDMnzY0uiRWVqRCpQ4lKgCydCjWrSplODQwcGBAAh', 'HobbsSalterSamsungSataliteSeboSennheiserServisSharpSiemensSKYSmegSmilightSONSonorousSonosSonyStovesSwanSylvaniaTechlinkTefalTeknixTJ', '0e46e5e7c2a7aca07365ecb6ca1e5a9e', '81-post-18-free-service-invoice-templates-in-word-and-excel-hloomcom-cool-math-gamesus']\n",
      "Furthest: ['\\U00100071', '\\U00100077', '201es', 'alsod', '\\U00100040', '\\U00100068', 'SpotlightCircaMy', 'accompagnés', '100x100px', 'Relationally']\n",
      "\n",
      "Word: filth\n",
      "Closest: ['filthy', 'foulness', 'excrement', 'dirtiness', 'vileness', 'squalor', 'cesspit', 'disgustingness', 'filthiness', 'ordure']\n",
      "Furthest: ['Single-Sign-On', 'Auto-MDIX', 'TACC', 'ITCA', 'NSMS', 'MentorNet', 'PortalGuard', 'IdenTrust', 'z114', 'Eurocopter']\n",
      "\n",
      "Word: 5min\n",
      "Closest: ['10min', '15min', '2min', '3min', '5mins', '20min', '10mins', '7min', '5-10min', '10-15min']\n",
      "Furthest: ['4.0For', 'Consorting', 'non-Wikipedia', 'Hussein-era', 'funeral-related', 'Surnamed', 'Fuson', 'OfficeSpeech', 'Noggle', 'yet-to-be-discovered']\n",
      "\n",
      "Word: partition\n",
      "Closest: ['partitions', 'partion', 'partitioning', 'Partition', 'parition', 'partiton', 'partitioned', 'partition.', 'partioning', 'partions']\n",
      "Furthest: ['Erick', 'Ichthus', 'Tianxiao', 'Startt', 'Haggstrom', 'Nordqvist', '---Anonymous', 'Noochie', 'exaggerated.Here', 'Stian']\n",
      "\n",
      "Word: save\n",
      "Closest: ['saving', 'saved', 'saves', 'Save', 'save.', 'tosave', 'save.I', 'conserve', 'sacrificing', 'economize']\n",
      "Furthest: ['IGEA', 'Recreative', 'NARB', 'XLR-11', 'AGCC', 'Markeri', 'DQP', 'LLCP', 'ISED', '1973a']\n",
      "\n",
      "Word: panera\n",
      "Closest: ['starbucks', 'quiznos', 'starbucks.', 'Panera', 'mcdonalds.', 'mcds', 'bread.', 'chickfila', 'wegmans', 'pizza.']\n",
      "Furthest: ['Emitters', 'Reinsurers', 'Papapetrou', 'Phoria', 'post-2006', 'Awdry', 'Corfield', 'AutoView', 'Valuer', 'Rank-Broadley']\n",
      "\n",
      "Word: attacked\n",
      "Closest: ['assaulted', 'ambushed', 'atacked', 'attacking', 'attcked', 'chased', 'Attacked', 'menaced', 'attacked.', 'terrorized']\n",
      "Furthest: ['moreProject', 'moreFull', 'StockOut', 'version1', '0Board', 'SCMG', 'version2', 'YesAdditional', 'moreRichard', 'moreRegister']\n",
      "\n",
      "Word: varying\n",
      "Closest: ['differing', 'varied', 'varing', 'Varying', 'varrying', 'various', 'different', 'ranging', 'widely-varying', 'differeing']\n",
      "Furthest: ['VARCHARCan', 'hereMake', 'LAKings', 'LetsGo', 'dady', 'CodeGo', \"'Let\", 'MUMU', 'now.claiming.message', \"'Take\"]\n",
      "\n",
      "Word: limon\n",
      "Closest: ['limón', 'limonada', 'limone', 'jugo', 'clementina', 'limonum', 'limonade', 'pepino', 'aurantifolia', 'agua']\n",
      "Furthest: ['PDSA', 'HomeFront', 'Apprentices', 'Commenting', 'HealthWatch', 'phase-out', 'ConservativeHome', '2011.If', 'control-oriented', 'CustomMade']\n",
      "\n",
      "Word: gras\n",
      "Closest: ['Gras', 'fois', 'veau', 'foie', \"'etat\", 'poivre', 'fraiche', 'résistance', 'etat', 'bouche']\n",
      "Furthest: ['Upholder', 'OneCode', 'TaqMan', 'Guidepost', 'LifeSpan', 'JMW', 'article.--', 'NeatReceipts', 'CHRONOS', 'PayNearMe']\n",
      "\n",
      "Word: reveal\n",
      "Closest: ['revealing', 'reveals', 'revealed', 'uncover', 'reaveal', 'divulge', 'unveil', 'uncovers', 'conceal', 'divulged']\n",
      "Furthest: ['Bussing', 'HardRock', 'FOCO', '57miles', 'KUPS', 'T.10', 'Liimatta', '12791', 'Symrna', '2.101']\n",
      "\n",
      "Word: multicolored\n",
      "Closest: ['multi-colored', 'multicoloured', 'multi-coloured', 'multi-hued', 'rainbow-colored', 'single-colored', 'brightly-colored', 'rainbow-hued', 'multi-patterned', 'multi-color']\n",
      "Furthest: ['Kinbrace', 'fhall', 'Strensham', 'NSAI', 'Romsey', 'CIPFA', 'Imker', 'Terowie', 'Aftersales', 'Tonbridge']\n",
      "\n",
      "Word: jockey\n",
      "Closest: ['jockeys', 'Jockey', 'jocky', 'racehorse', 'ex-jockey', 'reinsman', 'owner-trainer', 'jockies', 'steeplechasers', 'money-winning']\n",
      "Furthest: ['Jyllinge', 'Fantoft', 'Hjem', 'Norheimsund', 'UTSee', 'Skriv', 'CSNTM', 'MSEK', 'Velkommen', 'Aryl']\n",
      "\n",
      "Word: eaten\n",
      "Closest: ['ate', 'eatten', 'eaten.I', 'eaten.', 'eaten.The', 'eat', 'devoured', 'Eaten', 'consumed', 'munched']\n",
      "Furthest: ['Clarifying', 'Relationship-based', 'Vergence', 'Three-step', 'FS6', 'Glidepath', 'DivisionNew', 'Geosolutions', 'InformationFeatures', 'Vizion']\n",
      "\n",
      "Word: baja\n",
      "Closest: ['bajas', 'Baja', 'ensenada', 'jalisco', 'sahara', 'BAJA', 'tecate', 'mexicali', 'caribe', 'cali']\n",
      "Furthest: ['WeekCatawba', 'Bebris', 'Chamberlain', 'Peers', 'Stevereads', 'closed-doors', 'Harrow', 'theagency', 'Lords', 'Kalfin']\n",
      "\n",
      "Word: mere\n",
      "Closest: ['paltry', 'merely', 'measly', 'merest', 'mear', 'scant', 'miniscule', 'measley', 'trifling', 'puny']\n",
      "Furthest: ['Rispin', 'IHSP', 'officiating.Burial', 'doWhich', 'Keyvelop', 'Greets', 'ResponsesAuthor', 'Selects', 'BRUBECK', 'answerWhich']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "pretrained_model = load_facebook_model( \"C:\\\\Users\\\\ali\\\\OneDrive\\\\Desktop\\\\cc.en.300.bin\")\n",
    "\n",
    "\n",
    "# Test pretrained model\n",
    "pretrained_results = {}\n",
    "for word in random_words:\n",
    "    closest = pretrained_model.wv.most_similar(word, topn=10)\n",
    "    furthest = pretrained_model.wv.most_similar(negative=[word], topn=10)\n",
    "    pretrained_results[word] = {'closest': closest, 'furthest': furthest}\n",
    "\n",
    "# Print results\n",
    "for word, similar_words in pretrained_results.items():\n",
    "    print(\"Word:\", word)\n",
    "    print(\"Closest:\", [w[0] for w in similar_words['closest']])\n",
    "    print(\"Furthest:\", [w[0] for w in similar_words['furthest']])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
